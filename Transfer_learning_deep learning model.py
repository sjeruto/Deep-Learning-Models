# -*- coding: utf-8 -*-
"""ASGN_2_Part1_2_DL_13820434.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UfpGj9UR7yqSHIEAqrPbVmPc71jVOb7F

#Introduction
This notebook is split into two parts; Part A contains analysis of three models; inception_resnet v2, mobilenet_v3 and Nasnet. While Part B contains analysis of inception_resnet that has been fine tuned and presented using the food101 dataset.

#Importing data and necessary libaries
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

# Commented out IPython magic to ensure Python compatibility.
#Load library
import tensorflow as tf
from google.colab import drive
import numpy as np
import matplotlib.pyplot as plt
import requests
import tensorflow as tf
import matplotlib.image as img
# %matplotlib inline
import numpy as np
from collections import defaultdict
import collections
from shutil import copy
from shutil import copytree, rmtree
import tensorflow.keras.backend as K
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import os
import random
import tensorflow as tf
import tensorflow.keras.backend as K
from tensorflow.keras import regularizers
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.regularizers import l2
from tensorflow import keras
from tensorflow.keras import models
import cv2

drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# % cd /content/gdrive/MyDrive/DL_ASG_2

## Upload data
file_url = 'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz'
zip_dir = tf.keras.utils.get_file('food-101.tar.gz', origin=file_url, extract=True)
zip_dir

from pathlib import Path
import pathlib
import os.path
parent_dir = pathlib.Path(zip_dir).parent
parent_dir

! ls /root/.keras/datasets/food-101

image_dir = Path('/root/.keras/datasets/food-101/images')
image_dir

#os.listdir('food-101/images')

"""## Preparing dataset"""

import glob
#Create a dataframe
filepaths = list(image_dir.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))



print(filepaths)
print(labels)

import pandas as pd
#Create a pandas dataframe
filepaths_new = pd.Series(filepaths, name='Filepath').astype(str)
labels_new = pd.Series(labels, name='Label')

images = pd.concat([filepaths_new, labels_new], axis=1)

#Create Empty list and take a sample of 100 images in each category
category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(100, random_state=1))

image_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)

image_df

image_df['Label'].value_counts()

"""## Splitting data into train and test data"""

from sklearn.model_selection import train_test_split
##### Split data into train and test
train_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)

"""## Modelling

## Model 1: Inception_resnet_V3

#### Creating the generators for InceptionV3
"""

from tensorflow.keras.applications import inception_resnet_v2

## Creating generators
train_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input,
    validation_split=0.2
)

test_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input
)

train_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

#### Modelling
from tensorflow.keras.applications import InceptionV3
pretrained_model_Inception_resnet_V3 = tf.keras.applications.InceptionResNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)

pretrained_model_Inception_resnet_V3.trainable = False

inputs = pretrained_model_Inception_resnet_V3.input

x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model_Inception_resnet_V3.output)
x = tf.keras.layers.Dense(128, activation='relu')(x)

outputs = tf.keras.layers.Dense(101, activation='softmax')(x)

model = tf.keras.Model(inputs, outputs)


print(model.summary())

"""#### Model Training"""

##Training
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(
    train_images,
    validation_data=val_images,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

"""#### Model Results"""

results = model.evaluate(test_images, verbose=0)
print("Test Accuracy: {:.2f}%".format(results[1] * 100))

from sklearn.metrics import confusion_matrix, classification_report
predictions = np.argmax(model.predict(test_images), axis=1)

cm = confusion_matrix(test_images.labels, predictions)
clr = classification_report(test_images.labels, predictions, target_names=test_images.class_indices, zero_division=0)

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(30, 30))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)
plt.xticks(ticks=np.arange(101) + 0.5, labels=test_images.class_indices, rotation=90)
plt.yticks(ticks=np.arange(101) + 0.5, labels=test_images.class_indices, rotation=0)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

print("Classification Report:\n----------------------\n", clr)

"""## Model 2: mobilenet_v3

###Creating the generators for Mobilenet_v3
"""

train_generator1 = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,
    validation_split=0.2
)

test_generator1 = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input
)

train_images1 = train_generator1.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images1 = train_generator1.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images1 = test_generator1.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

#### Modelling
#from tensorflow.keras.applications import mobilenet_v3

pretrained_model_mobilenet_v3 = tf.keras.applications.MobileNetV3Small(
    input_shape= (224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling ='avg'
)

pretrained_model_mobilenet_v3.trainable = False

inputs1 = pretrained_model_mobilenet_v3.input

x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model_mobilenet_v3.output)
x = tf.keras.layers.Dense(128, activation='relu')(x)

outputs1 = tf.keras.layers.Dense(101, activation='softmax')(x)

model2 = tf.keras.Model(inputs1, outputs1)


print(model2.summary())

"""### Model Training

"""

##Training
model2.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history2 = model2.fit(
    train_images1,
    validation_data=val_images1,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

"""### Model Results"""

results2 = model2.evaluate(test_images1, verbose=0)
print("Test Accuracy: {:.2f}%".format(results2[1] * 100))

predictions2 = np.argmax(model2.predict(test_images1), axis=1)

cm = confusion_matrix(test_images1.labels, predictions2)
clr = classification_report(test_images1.labels, predictions2, target_names=test_images1.class_indices, zero_division=0)

plt.figure(figsize=(30, 30))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)
plt.xticks(ticks=np.arange(101) + 0.5, labels=test_images1.class_indices, rotation=90)
plt.yticks(ticks=np.arange(101) + 0.5, labels=test_images1.class_indices, rotation=0)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

"""# Model 3: Nasnet

## Creating the generators for Nasnet
"""

from tensorflow.keras.applications import nasnet

## Creating generators
train_generator2 = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.nasnet.preprocess_input,
    validation_split=0.2
)

test_generator2 = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.nasnet.preprocess_input
)

train_images2 = train_generator2.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images2 = train_generator2.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images2 = test_generator2.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

#### Modelling
from tensorflow.keras.applications import nasnet
pretrained_model_nasnet = tf.keras.applications.NASNetLarge(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)

pretrained_model_nasnet.trainable = False

inputs2 = pretrained_model_nasnet.input

x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model_nasnet.output)
x = tf.keras.layers.Dense(128, activation='relu')(x)

outputs2 = tf.keras.layers.Dense(101, activation='softmax')(x)

model3 = tf.keras.Model(inputs2, outputs2)


print(model3.summary())

"""## Model training"""

##Training
model3.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history3 = model3.fit(
    train_images2,
    validation_data=val_images2,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

"""## Model Results"""

results3 = model3.evaluate(test_images2, verbose=0)
print("Test Accuracy: {:.2f}%".format(results3[1] * 100))

predictions3 = np.argmax(model3.predict(test_images2), axis=1)

cm = confusion_matrix(test_images2.labels, predictions3)
clr = classification_report(test_images2.labels, predictions3, target_names=test_images2.class_indices, zero_division=0)

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(30, 30))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)
plt.xticks(ticks=np.arange(101) + 0.5, labels=test_images2.class_indices, rotation=90)
plt.yticks(ticks=np.arange(101) + 0.5, labels=test_images2.class_indices, rotation=0)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

"""# Part B: Fine tuning Inception resnet v3 which is the best model so far
experiment unfreezing on at least 2 different layers of the model.

## Pretrained model
"""

## Creating generators
train_generator4 = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input,
    validation_split=0.2
)

test_generator4 = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input
)

train_images4 = train_generator4.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images4 = train_generator4.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images4 = test_generator4.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

"""## Model training

####Building the model
"""

### Using Inception_resnet_v2
##Training top layer
Base_model_InceptionResNetV2 = tf.keras.applications.InceptionResNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)
#Freeze the model
Base_model_InceptionResNetV2.trainable = False

#Create a new model on top
inputs4 = Base_model_InceptionResNetV2.input

x = tf.keras.layers.Dense(128, activation='relu')(Base_model_InceptionResNetV2.output)
x = tf.keras.layers.Dense(128, activation='relu')(x)

outputs4 = tf.keras.layers.Dense(101, activation='softmax')(x)

Base_model = tf.keras.Model(inputs4, outputs4)


print(Base_model.summary())

"""####Training the top layer"""

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
## Train the model on new data
Base_model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history4 = Base_model.fit(
    train_images4,
    validation_data=val_images4,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

"""#### Fine tuning on the entire dataset"""

#Freeze the model
Base_model_InceptionResNetV2.trainable = True

## Recompile your model after you make any changes to the `trainable` attribute of any inner layer, 
#so that your changes are take into account
Base_model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history5 = Base_model.fit(
    train_images4,
    validation_data=val_images4,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

"""## Model Results"""

results4 = Base_model.evaluate(test_images4, verbose=0)
print("Test Accuracy: {:.2f}%".format(results4[1] * 100))

predictions4 = np.argmax(Base_model.predict(test_images4), axis=1)

cm = confusion_matrix(test_images4.labels, predictions4)
clr = classification_report(test_images4.labels, predictions4, target_names=test_images4.class_indices, zero_division=0)

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(30, 30))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)
plt.xticks(ticks=np.arange(101) + 0.5, labels=test_images4.class_indices, rotation=90)
plt.yticks(ticks=np.arange(101) + 0.5, labels=test_images4.class_indices, rotation=0)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()